{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as sim\n",
    "\n",
    "import config as config\n",
    "\n",
    "from models.N2N_Unet import N2N_Unet_DAS, N2N_Orig_Unet, Cut2Self, U_Net_origi, U_Net, TestNet\n",
    "from metric import Metric\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7872.)\n",
      "tensor(246.)\n",
      "tensor(26208.)\n",
      "tensor(819.)\n"
     ]
    }
   ],
   "source": [
    "def masking(img, percent):\n",
    "    num_pixels = img.shape[-3] * img.shape[-2] * img.shape[-1]\n",
    "    maskamount = int(np.round(num_pixels * percent))\n",
    "    mask = torch.zeros_like(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        masked_indices = torch.randperm(num_pixels)[:maskamount]\n",
    "        mask_tmp = torch.zeros(img.shape[-3] , img.shape[-2] , img.shape[-1])\n",
    "        # Pixel in Maske auf 1 setzen\n",
    "        mask_tmp.view(-1)[masked_indices] = 1\n",
    "        mask[i] = mask_tmp\n",
    "    return mask\n",
    "\n",
    "def kaput(img, percent):\n",
    "    num_pixels = img.shape[-2] * img.shape[-1]\n",
    "    maskamount = int(np.round(num_pixels * percent))\n",
    "    mask = torch.zeros_like(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        masked_indices = torch.randperm(num_pixels)[:maskamount]\n",
    "        mask_tmp = torch.zeros(img.shape[-3] , img.shape[-2] , img.shape[-1])\n",
    "        # Pixel in Maske auf 1 setzen\n",
    "        mask_tmp.view(-1)[masked_indices] = 1\n",
    "        mask[i] = mask_tmp\n",
    "    return mask\n",
    "\n",
    "t = torch.randn(32, 3, 128, 128)\n",
    "mask = masking(t, 0.005)\n",
    "print(torch.sum(mask))\n",
    "print(torch.sum(mask[0]))\n",
    "mask = kaput(t, 0.05)\n",
    "print(torch.sum(mask))\n",
    "print(torch.sum(mask[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0004\n",
    "changeLR_steps = 5000\n",
    "changeLR_rate = -0.5\n",
    "modi = 0\n",
    "use_scheduler = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_lambda(initial_lr, step_size, lr_decrement):\n",
    "    def lr_lambda(step):\n",
    "        return max(0.0, initial_lr - (step // step_size) * lr_decrement / initial_lr)\n",
    "    return lr_lambda\n",
    "\n",
    "def add_norm_noise(img, snr_db):\n",
    "    noise = torch.randn_like(img)\n",
    "    snr_linear = snr_db\n",
    "    Es = torch.sum(img**2)\n",
    "    En = torch.sum(noise**2)\n",
    "    alpha = torch.sqrt(Es/(snr_linear*En))\n",
    "    noise = img + noise * alpha\n",
    "    return noise, alpha.item()\n",
    "\n",
    "def masking(img, percent):\n",
    "    num_pixels = img.shape[-3] * img.shape[-2] * img.shape[-1]\n",
    "    maskamount = int(np.round(num_pixels * percent))\n",
    "    mask = torch.zeros_like(img)\n",
    "    for i in range(img.shape[0]):\n",
    "        masked_indices = torch.randperm(num_pixels)[:maskamount]\n",
    "        mask_tmp = torch.zeros(img.shape[-3] , img.shape[-2] , img.shape[-1])\n",
    "        # Pixel in Maske auf 1 setzen\n",
    "        mask_tmp.view(-1)[masked_indices] = 1\n",
    "        mask[i] = mask_tmp\n",
    "    return mask\n",
    "\n",
    "def calculate_loss(noise_imges, model, device):\n",
    "    lambda_inv = 2\n",
    "    mask = masking(noise_imges, 0.005).to(device)\n",
    "    marked_points = torch.sum(mask)\n",
    "    input = noise_imges * (1-mask) + (torch.normal(0, 0.2, size=noise_imges.shape).to(device) * mask)\n",
    "    denoised = model(noise_imges)\n",
    "    denoised_masked = model(input)\n",
    "    loss_rec = torch.mean((denoised-noise_imges)**2) # mse(denoised, noise_images)\n",
    "    loss_inv = torch.sum(mask*(denoised-denoised_masked)**2)# mse(denoised, denoised_mask)\n",
    "    loss = loss_rec + lambda_inv * (loss_inv/marked_points).sqrt()\n",
    "    if math.isnan(loss):\n",
    "        print(f\"{loss_rec} + {loss_inv} * {(loss_inv/marked_points).sqrt()}, marked_points: {marked_points}\")\n",
    "    return loss, denoised, mask, loss_rec, loss_inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() == 1:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "else:\n",
    "    device = \"cuda:3\"\n",
    "\n",
    "celeba_dir = config.celeba_dir\n",
    "\n",
    "transform_noise = transforms.Compose([\n",
    "    #transforms.RandomResizedCrop((128,128)),\n",
    "    transforms.CenterCrop((128,128)),\n",
    "    #transforms.Resize((512,512)), #for self2self\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.float()),\n",
    "    transforms.Lambda(lambda x:  x * 2 -1),\n",
    "    ])\n",
    "print(\"lade Datens√§tze ...\")\n",
    "dataset_all = datasets.CelebA(root=celeba_dir, split='train', download=False, transform=transform_noise)\n",
    "\n",
    "dataset_validate_all = datasets.CelebA(root=celeba_dir, split='valid', download=False, transform=transform_noise)\n",
    "\n",
    "dataset_test_all = datasets.CelebA(root=celeba_dir, split='test', download=False, transform=transform_noise)\n",
    "\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "dataset = torch.utils.data.Subset(dataset_all, list(range(6400)))\n",
    "dataset_validate = torch.utils.data.Subset(dataset_validate_all, list(range(640)))\n",
    "dataset_test = torch.utils.data.Subset(dataset_test_all, list(range(640)))\n",
    "dataLoader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "dataLoader_validate = DataLoader(dataset_validate, batch_size=32, shuffle=False)\n",
    "dataLoader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "if torch.cuda.device_count() == 1:\n",
    "    model = N2N_Orig_Unet(3,3).to(device) #default\n",
    "else:\n",
    "    model = U_Net(in_chanel=3, first_out_chanel=96, batchNorm=True).to(device)\n",
    "\n",
    "#configAtr = getattr(config, methode) #config.methode wobei methode ein string ist\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "if use_scheduler:\n",
    "    lr_lambda = get_lr_lambda(lr, changeLR_steps, changeLR_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "else:\n",
    "    scheduler = None\n",
    "\n",
    "print(\"fertig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataLoader, optimizer, scheduler, device, model, mode):\n",
    "    global modi\n",
    "    global use_scheduler\n",
    "    loss_log = []\n",
    "    psnr_log = []\n",
    "    original_psnr_log = []\n",
    "    sim_log = []\n",
    "    loss_rec_log = []\n",
    "    loss_inv_log = []\n",
    "    for batch_idx, (original, label) in enumerate((dataLoader)):#tqdm\n",
    "        original = original.to(device)\n",
    "        noise_images, sigma = add_norm_noise(original, 2)\n",
    "        noise_images = noise_images.to(device)\n",
    "\n",
    "        if mode==\"test\" or mode ==\"validate\":\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                #n2same:\n",
    "                denoised = model(noise_images)\n",
    "                #n2info:\n",
    "                \"\"\"\n",
    "                if mode==\"test\":\n",
    "                    denoised = model(noise_images)\n",
    "                else:\n",
    "                    #loss, denoised, loss_rec, loss_inv, marked_pixel = n2same(noise_images, device, model, lambda_inv)\n",
    "                    loss, denoised, loss_rec, loss_inv, marked_pixel = n2info(noise_images, model, device, sigma_info)\n",
    "                    all_marked += marked_pixel\n",
    "                    lex += loss_rec\n",
    "                    lin += loss_inv\n",
    "                    n_partition = (denoised-noise_images).view(denoised.shape[0], -1) # (b, c*w*h)\n",
    "                    n_partition = torch.sort(n_partition, dim=1).values #descending=False\n",
    "                    n = torch.cat((n, n_partition), dim=0)\n",
    "                    if batch_idx == len(dataLoader)-1:\n",
    "                        e_l = 0\n",
    "                        for i in range(config.methodes['n2info']['predictions']): #kmc\n",
    "                            #to big for torch.multinomial if all pictures from validation should be used\n",
    "                            #samples = torch.tensor(torch.multinomial(n.view(-1), n.shape[1], replacement=True))#.view(1, n.shape[1])\n",
    "                            #samples = torch.sort(samples).values\n",
    "                            samples = np.sort(np.random.choice((n.cpu()).reshape(-1),[1, n.shape[1]])) #(1,49152)\n",
    "                            e_l += torch.mean((n-torch.from_numpy(samples).to(device))**2)\n",
    "                        lex = lex / (len(dataLoader) * denoised.shape[0])\n",
    "                        lin = lin / all_marked\n",
    "                        e_l = e_l / config.methodes['n2info']['predictions']\n",
    "                        #estimated_sigma = (lin)**0.5 + (lin + lex-e_l)**0.5 #inplementation from original github of noise2info\n",
    "                        m = len(dataLoader) * denoised.shape[0] *3*128*128 #TODO: is m right?\n",
    "                        estimated_sigma = lex + (lex**2 + m *(lin-e_l))**0.5/m #from paper\n",
    "                        print('new sigma_loss is ', estimated_sigma)\n",
    "                        if 0 < estimated_sigma < sigma_info:\n",
    "                            sigma_info = float(estimated_sigma)\n",
    "                            print('sigma_loss updated to ', estimated_sigma)\n",
    "                \"\"\"\n",
    "                        \n",
    "        else:\n",
    "            model.train()\n",
    "            #original, noise_images are only important if n2void\n",
    "            loss, denoised, mask, loss_rec, loss_inv = calculate_loss(noise_images, model, device)\n",
    "            loss_rec_log.append(loss_rec.item())\n",
    "            loss_inv_log.append(loss_inv.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if use_scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "        #log Data\n",
    "        original_psnr_batch = Metric.calculate_psnr(original, denoised)\n",
    "        denoised = (denoised-denoised.min())  / (denoised.max() - denoised.min())\n",
    "        noise_images = (noise_images-noise_images.min())  / (noise_images.max() - noise_images.min())\n",
    "        original = (original-original.min())  / (original.max() - original.min())\n",
    "        psnr_batch = Metric.calculate_psnr(original, denoised)\n",
    "        similarity_batch, diff_picture = Metric.calculate_similarity(original, denoised)\n",
    "        if \"train\" in mode:\n",
    "            loss_log.append(loss.item())\n",
    "        psnr_log.append(psnr_batch.item())\n",
    "        original_psnr_log.append(original_psnr_batch.item())\n",
    "        sim_log.append(similarity_batch)    \n",
    "    \n",
    "    return loss_log, psnr_log, original_psnr_log, sim_log, loss_rec_log, loss_inv_log\n",
    "\n",
    "\n",
    "loss_rec_log = []\n",
    "loss_inv_log = []\n",
    "for epoch in tqdm(range(50)):\n",
    "    \n",
    "    loss, psnr, original_psnr_log, similarity, loss_rec, loss_inv = train(dataLoader, optimizer, scheduler, device, model, mode=\"train\")\n",
    "    loss_rec_log.append(loss_rec)\n",
    "    loss_inv_log.append(loss_inv)\n",
    "    \n",
    "    if math.isnan(loss[-1]):\n",
    "        break\n",
    "\n",
    "    loss_val, psnr_val, original_psnr_log_val, similarity_val, _, _ = train(dataLoader_validate, optimizer, scheduler, device, model, mode=\"validate\")\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\"\n",
    "          f\"Train: loss={Metric.avg_list(loss):.5f}, psnr={Metric.avg_list(psnr):.5f}, psnr_orig={Metric.avg_list(original_psnr_log):.5f}, similarity={Metric.avg_list(similarity):.5f}\\n\"\n",
    "          f\"Validate: loss={0.00000}, psnr={Metric.avg_list(psnr_val):.5f}, psnr_orig={Metric.avg_list(original_psnr_log_val):.5f}, similarity={Metric.avg_list(similarity_val):.5f}\")\n",
    "    \n",
    "    \n",
    "loss_test, psnr_test, original_psnr_log_test, similarity_test, _, _ = train(dataLoader_test, optimizer, scheduler, device, model, mode=\"test\")\n",
    "\n",
    "print(f\"Test: loss={Metric.avg_list(loss_test):.5f}, psnr={Metric.avg_list(psnr_test):.5f}, similarity={Metric.avg_list(similarity_test):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot loss_rec_log\n",
    "plt.plot(range(len(loss_rec_log)), loss_rec_log, label='Reconstruction Loss')\n",
    "\n",
    "# Plot loss_inv_log\n",
    "plt.plot(range(len(loss_inv_log)), loss_inv_log, label='Inversion Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Reconstruction and Inversion Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "original, label = next(iter(dataLoader_test))\n",
    "original = original.to(device)\n",
    "noise_images, sigma = add_norm_noise(original, 2)\n",
    "noise_images = noise_images.to(device)\n",
    "denoised = model(noise_images)\n",
    "comparison = torch.cat((original[:4], denoised[:4], noise_images[:4]), dim=0)\n",
    "grid = make_grid(comparison, nrow=4, normalize=False).cpu()\n",
    "\n",
    "plt.imshow(grid.permute(1, 2, 0))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "denoise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
